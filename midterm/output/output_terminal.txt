Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by under sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0:  99 / class 1:  99
balanced testing  data class 0:  31 / class 1:  31
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 17 Accuracy: 0.8065
Run KNN by Min-Max normalization method / k value = 22 Accuracy: 0.8387
Run KNN by Z-score standard      method / k value = 10 Accuracy: 0.8871

labA use Z-score method has the highest accurancy.
accuracy: 0.8871 / k = 10

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by under sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 107 / class 1: 107
balanced testing  data class 0:  23 / class 1:  23
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  8 Accuracy: 0.8043
Run KNN by Min-Max normalization method / k value =  1 Accuracy: 0.7826
Run KNN by Z-score standard      method / k value = 16 Accuracy: 0.8043

labB use original method has the highest accurancy.
accuracy: 0.8043 / k = 8

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7941
Run random forest by Min-Max normalization method / Accuracy: 0.7574
Run random forest by Z-score standard      method / Accuracy: 0.7794

labA use original method has the highest accurancy.
accuracy: 0.7941

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8015
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.8309

labA use Z-score method has the highest accurancy.
accuracy: 0.8309

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8382
Run random forest by Min-Max normalization method / Accuracy: 0.7794
Run random forest by Z-score standard      method / Accuracy: 0.8015

labA use original method has the highest accurancy.
accuracy: 0.8382

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8382
Run random forest by Min-Max normalization method / Accuracy: 0.7353
Run random forest by Z-score standard      method / Accuracy: 0.8015

labA use original method has the highest accurancy.
accuracy: 0.8382

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8088
Run random forest by Min-Max normalization method / Accuracy: 0.7426
Run random forest by Z-score standard      method / Accuracy: 0.8162

labA use Z-score method has the highest accurancy.
accuracy: 0.8162

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8382
Run random forest by Min-Max normalization method / Accuracy: 0.7426
Run random forest by Z-score standard      method / Accuracy: 0.7721

labA use original method has the highest accurancy.
accuracy: 0.8382

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7647
Run random forest by Min-Max normalization method / Accuracy: 0.7647
Run random forest by Z-score standard      method / Accuracy: 0.8015

labA use Z-score method has the highest accurancy.
accuracy: 0.8015

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8529
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.8750

labA use Z-score method has the highest accurancy.
accuracy: 0.8750

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8309
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.8382

labA use Z-score method has the highest accurancy.
accuracy: 0.8382

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8235
Run random forest by Min-Max normalization method / Accuracy: 0.7353
Run random forest by Z-score standard      method / Accuracy: 0.8309

labA use Z-score method has the highest accurancy.
accuracy: 0.8309

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8015
Run random forest by Min-Max normalization method / Accuracy: 0.7426
Run random forest by Z-score standard      method / Accuracy: 0.7794

labA use original method has the highest accurancy.
accuracy: 0.8015

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7353
Run random forest by Min-Max normalization method / Accuracy: 0.7353
Run random forest by Z-score standard      method / Accuracy: 0.8088

labA use Z-score method has the highest accurancy.
accuracy: 0.8088

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8088
Run random forest by Min-Max normalization method / Accuracy: 0.7574
Run random forest by Z-score standard      method / Accuracy: 0.8162

labA use Z-score method has the highest accurancy.
accuracy: 0.8162

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7868
Run random forest by Min-Max normalization method / Accuracy: 0.7353
Run random forest by Z-score standard      method / Accuracy: 0.8088

labA use Z-score method has the highest accurancy.
accuracy: 0.8088

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8309
Run random forest by Min-Max normalization method / Accuracy: 0.7353
Run random forest by Z-score standard      method / Accuracy: 0.8382

labA use Z-score method has the highest accurancy.
accuracy: 0.8382

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8162
Run random forest by Min-Max normalization method / Accuracy: 0.7721
Run random forest by Z-score standard      method / Accuracy: 0.7868

labA use original method has the highest accurancy.
accuracy: 0.8162

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7941
Run random forest by Min-Max normalization method / Accuracy: 0.7721
Run random forest by Z-score standard      method / Accuracy: 0.7941

labA use original method has the highest accurancy.
accuracy: 0.7941

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7721
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.7941

labA use Z-score method has the highest accurancy.
accuracy: 0.7941

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7868
Run random forest by Min-Max normalization method / Accuracy: 0.7279
Run random forest by Z-score standard      method / Accuracy: 0.7647

labA use original method has the highest accurancy.
accuracy: 0.7868

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7647
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.8088

labA use Z-score method has the highest accurancy.
accuracy: 0.8088

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8162
Run random forest by Min-Max normalization method / Accuracy: 0.7206
Run random forest by Z-score standard      method / Accuracy: 0.7794

labA use original method has the highest accurancy.
accuracy: 0.8162

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8309
Run random forest by Min-Max normalization method / Accuracy: 0.7721
Run random forest by Z-score standard      method / Accuracy: 0.7941

labA use original method has the highest accurancy.
accuracy: 0.8309

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8676
Run random forest by Min-Max normalization method / Accuracy: 0.7721
Run random forest by Z-score standard      method / Accuracy: 0.7941

labA use original method has the highest accurancy.
accuracy: 0.8676

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7868
Run random forest by Min-Max normalization method / Accuracy: 0.7647
Run random forest by Z-score standard      method / Accuracy: 0.7868

labA use original method has the highest accurancy.
accuracy: 0.7868

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7941
Run random forest by Min-Max normalization method / Accuracy: 0.7206
Run random forest by Z-score standard      method / Accuracy: 0.7647

labA use original method has the highest accurancy.
accuracy: 0.7941

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8456
Run random forest by Min-Max normalization method / Accuracy: 0.7868
Run random forest by Z-score standard      method / Accuracy: 0.8309

labA use original method has the highest accurancy.
accuracy: 0.8456

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8235
Run random forest by Min-Max normalization method / Accuracy: 0.7206
Run random forest by Z-score standard      method / Accuracy: 0.8088

labA use original method has the highest accurancy.
accuracy: 0.8235

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8824
Run random forest by Min-Max normalization method / Accuracy: 0.7426
Run random forest by Z-score standard      method / Accuracy: 0.8309

labA use original method has the highest accurancy.
accuracy: 0.8824

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8235
Run random forest by Min-Max normalization method / Accuracy: 0.7721
Run random forest by Z-score standard      method / Accuracy: 0.8015

labA use original method has the highest accurancy.
accuracy: 0.8235

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8235
Run random forest by Min-Max normalization method / Accuracy: 0.7647
Run random forest by Z-score standard      method / Accuracy: 0.8015

labA use original method has the highest accurancy.
accuracy: 0.8235

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7868
Run random forest by Min-Max normalization method / Accuracy: 0.7353
Run random forest by Z-score standard      method / Accuracy: 0.7941

labA use Z-score method has the highest accurancy.
accuracy: 0.7941

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8456
Run random forest by Min-Max normalization method / Accuracy: 0.7794
Run random forest by Z-score standard      method / Accuracy: 0.8309

labA use original method has the highest accurancy.
accuracy: 0.8456

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8235
Run random forest by Min-Max normalization method / Accuracy: 0.7868
Run random forest by Z-score standard      method / Accuracy: 0.8382

labA use Z-score method has the highest accurancy.
accuracy: 0.8382

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8456
Run random forest by Min-Max normalization method / Accuracy: 0.7574
Run random forest by Z-score standard      method / Accuracy: 0.7868

labA use original method has the highest accurancy.
accuracy: 0.8456

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8603
Run random forest by Min-Max normalization method / Accuracy: 0.8015
Run random forest by Z-score standard      method / Accuracy: 0.8603

labA use original method has the highest accurancy.
accuracy: 0.8603

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7868
Run random forest by Min-Max normalization method / Accuracy: 0.7426
Run random forest by Z-score standard      method / Accuracy: 0.7941

labA use Z-score method has the highest accurancy.
accuracy: 0.7941

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8088
Run random forest by Min-Max normalization method / Accuracy: 0.7426
Run random forest by Z-score standard      method / Accuracy: 0.8382

labA use Z-score method has the highest accurancy.
accuracy: 0.8382

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8088
Run random forest by Min-Max normalization method / Accuracy: 0.7721
Run random forest by Z-score standard      method / Accuracy: 0.8088

labA use original method has the highest accurancy.
accuracy: 0.8088

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8309
Run random forest by Min-Max normalization method / Accuracy: 0.7353
Run random forest by Z-score standard      method / Accuracy: 0.8235

labA use original method has the highest accurancy.
accuracy: 0.8309

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7794
Run random forest by Min-Max normalization method / Accuracy: 0.7426
Run random forest by Z-score standard      method / Accuracy: 0.8235

labA use Z-score method has the highest accurancy.
accuracy: 0.8235

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7647
Run random forest by Min-Max normalization method / Accuracy: 0.7279
Run random forest by Z-score standard      method / Accuracy: 0.7868

labA use Z-score method has the highest accurancy.
accuracy: 0.7868

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7868
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.7941

labA use Z-score method has the highest accurancy.
accuracy: 0.7941

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8382
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.8015

labA use original method has the highest accurancy.
accuracy: 0.8382

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7868
Run random forest by Min-Max normalization method / Accuracy: 0.7574
Run random forest by Z-score standard      method / Accuracy: 0.8162

labA use Z-score method has the highest accurancy.
accuracy: 0.8162

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8088
Run random forest by Min-Max normalization method / Accuracy: 0.7132
Run random forest by Z-score standard      method / Accuracy: 0.8088

labA use original method has the highest accurancy.
accuracy: 0.8088

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8015
Run random forest by Min-Max normalization method / Accuracy: 0.7794
Run random forest by Z-score standard      method / Accuracy: 0.8015

labA use original method has the highest accurancy.
accuracy: 0.8015

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7868
Run random forest by Min-Max normalization method / Accuracy: 0.7647
Run random forest by Z-score standard      method / Accuracy: 0.8162

labA use Z-score method has the highest accurancy.
accuracy: 0.8162

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8015
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.8162

labA use Z-score method has the highest accurancy.
accuracy: 0.8162

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8088
Run random forest by Min-Max normalization method / Accuracy: 0.7941
Run random forest by Z-score standard      method / Accuracy: 0.8162

labA use Z-score method has the highest accurancy.
accuracy: 0.8162

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7721
Run random forest by Min-Max normalization method / Accuracy: 0.7868
Run random forest by Z-score standard      method / Accuracy: 0.8088

labA use Z-score method has the highest accurancy.
accuracy: 0.8088

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7941
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.8015

labA use Z-score method has the highest accurancy.
accuracy: 0.8015

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7941
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.8235

labA use Z-score method has the highest accurancy.
accuracy: 0.8235

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8603
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.8309

labA use original method has the highest accurancy.
accuracy: 0.8603

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7721
Run random forest by Min-Max normalization method / Accuracy: 0.7059
Run random forest by Z-score standard      method / Accuracy: 0.8015

labA use Z-score method has the highest accurancy.
accuracy: 0.8015

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8162
Run random forest by Min-Max normalization method / Accuracy: 0.7353
Run random forest by Z-score standard      method / Accuracy: 0.7721

labA use original method has the highest accurancy.
accuracy: 0.8162

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7206
Run random forest by Min-Max normalization method / Accuracy: 0.7426
Run random forest by Z-score standard      method / Accuracy: 0.8015

labA use Z-score method has the highest accurancy.
accuracy: 0.8015

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8382
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.7941

labA use original method has the highest accurancy.
accuracy: 0.8382

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8309
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.7721

labA use original method has the highest accurancy.
accuracy: 0.8309

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8309
Run random forest by Min-Max normalization method / Accuracy: 0.7353
Run random forest by Z-score standard      method / Accuracy: 0.8235

labA use original method has the highest accurancy.
accuracy: 0.8309

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8015
Run random forest by Min-Max normalization method / Accuracy: 0.7647
Run random forest by Z-score standard      method / Accuracy: 0.8088

labA use Z-score method has the highest accurancy.
accuracy: 0.8088

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7794
Run random forest by Min-Max normalization method / Accuracy: 0.7426
Run random forest by Z-score standard      method / Accuracy: 0.7941

labA use Z-score method has the highest accurancy.
accuracy: 0.7941

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8456
Run random forest by Min-Max normalization method / Accuracy: 0.7279
Run random forest by Z-score standard      method / Accuracy: 0.8088

labA use original method has the highest accurancy.
accuracy: 0.8456

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7868
Run random forest by Min-Max normalization method / Accuracy: 0.7353
Run random forest by Z-score standard      method / Accuracy: 0.8162

labA use Z-score method has the highest accurancy.
accuracy: 0.8162

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8382
Run random forest by Min-Max normalization method / Accuracy: 0.7721
Run random forest by Z-score standard      method / Accuracy: 0.8382

labA use original method has the highest accurancy.
accuracy: 0.8382

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8162
Run random forest by Min-Max normalization method / Accuracy: 0.7279
Run random forest by Z-score standard      method / Accuracy: 0.7868

labA use original method has the highest accurancy.
accuracy: 0.8162

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8015
Run random forest by Min-Max normalization method / Accuracy: 0.7132
Run random forest by Z-score standard      method / Accuracy: 0.8529

labA use Z-score method has the highest accurancy.
accuracy: 0.8529

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8309
Run random forest by Min-Max normalization method / Accuracy: 0.7574
Run random forest by Z-score standard      method / Accuracy: 0.8235

labA use original method has the highest accurancy.
accuracy: 0.8309

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8088
Run random forest by Min-Max normalization method / Accuracy: 0.7794
Run random forest by Z-score standard      method / Accuracy: 0.8015

labA use original method has the highest accurancy.
accuracy: 0.8088

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7941
Run random forest by Min-Max normalization method / Accuracy: 0.7279
Run random forest by Z-score standard      method / Accuracy: 0.7426

labA use original method has the highest accurancy.
accuracy: 0.7941

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8235
Run random forest by Min-Max normalization method / Accuracy: 0.7353
Run random forest by Z-score standard      method / Accuracy: 0.8088

labA use original method has the highest accurancy.
accuracy: 0.8235

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8088
Run random forest by Min-Max normalization method / Accuracy: 0.7574
Run random forest by Z-score standard      method / Accuracy: 0.7794

labA use original method has the highest accurancy.
accuracy: 0.8088

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7279
Run random forest by Min-Max normalization method / Accuracy: 0.6985
Run random forest by Z-score standard      method / Accuracy: 0.7500

labA use Z-score method has the highest accurancy.
accuracy: 0.7500

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8309
Run random forest by Min-Max normalization method / Accuracy: 0.7868
Run random forest by Z-score standard      method / Accuracy: 0.8088

labA use original method has the highest accurancy.
accuracy: 0.8309

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8088
Run random forest by Min-Max normalization method / Accuracy: 0.7426
Run random forest by Z-score standard      method / Accuracy: 0.8088

labA use original method has the highest accurancy.
accuracy: 0.8088

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7794
Run random forest by Min-Max normalization method / Accuracy: 0.7353
Run random forest by Z-score standard      method / Accuracy: 0.7794

labA use original method has the highest accurancy.
accuracy: 0.7794

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8015
Run random forest by Min-Max normalization method / Accuracy: 0.7206
Run random forest by Z-score standard      method / Accuracy: 0.7721

labA use original method has the highest accurancy.
accuracy: 0.8015

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8088
Run random forest by Min-Max normalization method / Accuracy: 0.7132
Run random forest by Z-score standard      method / Accuracy: 0.8235

labA use Z-score method has the highest accurancy.
accuracy: 0.8235

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7941
Run random forest by Min-Max normalization method / Accuracy: 0.7279
Run random forest by Z-score standard      method / Accuracy: 0.8015

labA use Z-score method has the highest accurancy.
accuracy: 0.8015

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8309
Run random forest by Min-Max normalization method / Accuracy: 0.7868
Run random forest by Z-score standard      method / Accuracy: 0.8382

labA use Z-score method has the highest accurancy.
accuracy: 0.8382

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7941
Run random forest by Min-Max normalization method / Accuracy: 0.7206
Run random forest by Z-score standard      method / Accuracy: 0.7353

labA use original method has the highest accurancy.
accuracy: 0.7941

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7794
Run random forest by Min-Max normalization method / Accuracy: 0.7647
Run random forest by Z-score standard      method / Accuracy: 0.7794

labA use original method has the highest accurancy.
accuracy: 0.7794

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8162
Run random forest by Min-Max normalization method / Accuracy: 0.7279
Run random forest by Z-score standard      method / Accuracy: 0.8088

labA use original method has the highest accurancy.
accuracy: 0.8162

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8015
Run random forest by Min-Max normalization method / Accuracy: 0.7647
Run random forest by Z-score standard      method / Accuracy: 0.7794

labA use original method has the highest accurancy.
accuracy: 0.8015

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7794
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.7941

labA use Z-score method has the highest accurancy.
accuracy: 0.7941

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8235
Run random forest by Min-Max normalization method / Accuracy: 0.7426
Run random forest by Z-score standard      method / Accuracy: 0.8309

labA use Z-score method has the highest accurancy.
accuracy: 0.8309

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8162
Run random forest by Min-Max normalization method / Accuracy: 0.7574
Run random forest by Z-score standard      method / Accuracy: 0.7868

labA use original method has the highest accurancy.
accuracy: 0.8162

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8088
Run random forest by Min-Max normalization method / Accuracy: 0.7794
Run random forest by Z-score standard      method / Accuracy: 0.8088

labA use original method has the highest accurancy.
accuracy: 0.8088

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8015
Run random forest by Min-Max normalization method / Accuracy: 0.7647
Run random forest by Z-score standard      method / Accuracy: 0.8015

labA use original method has the highest accurancy.
accuracy: 0.8015

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7794
Run random forest by Min-Max normalization method / Accuracy: 0.7426
Run random forest by Z-score standard      method / Accuracy: 0.7941

labA use Z-score method has the highest accurancy.
accuracy: 0.7941

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7794
Run random forest by Min-Max normalization method / Accuracy: 0.7426
Run random forest by Z-score standard      method / Accuracy: 0.8309

labA use Z-score method has the highest accurancy.
accuracy: 0.8309

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8015
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.7941

labA use original method has the highest accurancy.
accuracy: 0.8015

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7941
Run random forest by Min-Max normalization method / Accuracy: 0.7868
Run random forest by Z-score standard      method / Accuracy: 0.7868

labA use original method has the highest accurancy.
accuracy: 0.7941

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8162
Run random forest by Min-Max normalization method / Accuracy: 0.7941
Run random forest by Z-score standard      method / Accuracy: 0.8309

labA use Z-score method has the highest accurancy.
accuracy: 0.8309

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7794
Run random forest by Min-Max normalization method / Accuracy: 0.8015
Run random forest by Z-score standard      method / Accuracy: 0.7647

labA use Min-Max method has the highest accurancy.
accuracy: 0.8015

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8015
Run random forest by Min-Max normalization method / Accuracy: 0.7426
Run random forest by Z-score standard      method / Accuracy: 0.7794

labA use original method has the highest accurancy.
accuracy: 0.8015

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7941
Run random forest by Min-Max normalization method / Accuracy: 0.7721
Run random forest by Z-score standard      method / Accuracy: 0.8676

labA use Z-score method has the highest accurancy.
accuracy: 0.8676

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8088
Run random forest by Min-Max normalization method / Accuracy: 0.7647
Run random forest by Z-score standard      method / Accuracy: 0.8162

labA use Z-score method has the highest accurancy.
accuracy: 0.8162

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7794
Run random forest by Min-Max normalization method / Accuracy: 0.7647
Run random forest by Z-score standard      method / Accuracy: 0.7353

labA use original method has the highest accurancy.
accuracy: 0.7794

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.7868
Run random forest by Min-Max normalization method / Accuracy: 0.7647
Run random forest by Z-score standard      method / Accuracy: 0.8015

labA use Z-score method has the highest accurancy.
accuracy: 0.8015

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99

Balancing data by over sampling...
original training data class 0: 194 / class 1:  99
original testing  data class 0:  68 / class 1:  31
balanced training data class 0: 194 / class 1: 194
balanced testing  data class 0:  68 / class 1:  68
===========================================================================
Run random forest by original              method / Accuracy: 0.8456
Run random forest by Min-Max normalization method / Accuracy: 0.7721
Run random forest by Z-score standard      method / Accuracy: 0.7941

labA use original method has the highest accurancy.
accuracy: 0.8456

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7414
Run random forest by Min-Max normalization method / Accuracy: 0.7414
Run random forest by Z-score standard      method / Accuracy: 0.7414

labB use original method has the highest accurancy.
accuracy: 0.7414

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7069
Run random forest by Min-Max normalization method / Accuracy: 0.7069
Run random forest by Z-score standard      method / Accuracy: 0.7414

labB use Z-score method has the highest accurancy.
accuracy: 0.7414

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7414
Run random forest by Min-Max normalization method / Accuracy: 0.7241
Run random forest by Z-score standard      method / Accuracy: 0.7414

labB use original method has the highest accurancy.
accuracy: 0.7414

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7414
Run random forest by Min-Max normalization method / Accuracy: 0.8276
Run random forest by Z-score standard      method / Accuracy: 0.7759

labB use Min-Max method has the highest accurancy.
accuracy: 0.8276

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7414
Run random forest by Min-Max normalization method / Accuracy: 0.7759
Run random forest by Z-score standard      method / Accuracy: 0.7069

labB use Min-Max method has the highest accurancy.
accuracy: 0.7759

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7759
Run random forest by Min-Max normalization method / Accuracy: 0.7586
Run random forest by Z-score standard      method / Accuracy: 0.7586

labB use original method has the highest accurancy.
accuracy: 0.7759

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7069
Run random forest by Min-Max normalization method / Accuracy: 0.7586
Run random forest by Z-score standard      method / Accuracy: 0.6897

labB use Min-Max method has the highest accurancy.
accuracy: 0.7586

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7069
Run random forest by Min-Max normalization method / Accuracy: 0.7586
Run random forest by Z-score standard      method / Accuracy: 0.7586

labB use Min-Max method has the highest accurancy.
accuracy: 0.7586

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7414
Run random forest by Min-Max normalization method / Accuracy: 0.7069
Run random forest by Z-score standard      method / Accuracy: 0.7759

labB use Z-score method has the highest accurancy.
accuracy: 0.7759

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.8103
Run random forest by Min-Max normalization method / Accuracy: 0.6897
Run random forest by Z-score standard      method / Accuracy: 0.7586

labB use original method has the highest accurancy.
accuracy: 0.8103

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7241
Run random forest by Min-Max normalization method / Accuracy: 0.7586
Run random forest by Z-score standard      method / Accuracy: 0.7414

labB use Min-Max method has the highest accurancy.
accuracy: 0.7586

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.8276
Run random forest by Min-Max normalization method / Accuracy: 0.7241
Run random forest by Z-score standard      method / Accuracy: 0.7414

labB use original method has the highest accurancy.
accuracy: 0.8276

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.8103
Run random forest by Min-Max normalization method / Accuracy: 0.7414
Run random forest by Z-score standard      method / Accuracy: 0.7931

labB use original method has the highest accurancy.
accuracy: 0.8103

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7414
Run random forest by Min-Max normalization method / Accuracy: 0.6897
Run random forest by Z-score standard      method / Accuracy: 0.6379

labB use original method has the highest accurancy.
accuracy: 0.7414

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7069
Run random forest by Min-Max normalization method / Accuracy: 0.6724
Run random forest by Z-score standard      method / Accuracy: 0.6724

labB use original method has the highest accurancy.
accuracy: 0.7069

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7241
Run random forest by Min-Max normalization method / Accuracy: 0.7586
Run random forest by Z-score standard      method / Accuracy: 0.7414

labB use Min-Max method has the highest accurancy.
accuracy: 0.7586

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7931
Run random forest by Min-Max normalization method / Accuracy: 0.7414
Run random forest by Z-score standard      method / Accuracy: 0.7414

labB use original method has the highest accurancy.
accuracy: 0.7931

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7586
Run random forest by Min-Max normalization method / Accuracy: 0.8103
Run random forest by Z-score standard      method / Accuracy: 0.7241

labB use Min-Max method has the highest accurancy.
accuracy: 0.8103

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7241
Run random forest by Min-Max normalization method / Accuracy: 0.7759
Run random forest by Z-score standard      method / Accuracy: 0.7414

labB use Min-Max method has the highest accurancy.
accuracy: 0.7759

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7414
Run random forest by Min-Max normalization method / Accuracy: 0.7586
Run random forest by Z-score standard      method / Accuracy: 0.7241

labB use Min-Max method has the highest accurancy.
accuracy: 0.7586

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.8103
Run random forest by Min-Max normalization method / Accuracy: 0.7759
Run random forest by Z-score standard      method / Accuracy: 0.7586

labB use original method has the highest accurancy.
accuracy: 0.8103

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7069
Run random forest by Min-Max normalization method / Accuracy: 0.6897
Run random forest by Z-score standard      method / Accuracy: 0.7414

labB use Z-score method has the highest accurancy.
accuracy: 0.7414

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.6724
Run random forest by Min-Max normalization method / Accuracy: 0.7586
Run random forest by Z-score standard      method / Accuracy: 0.7759

labB use Z-score method has the highest accurancy.
accuracy: 0.7759

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7759
Run random forest by Min-Max normalization method / Accuracy: 0.7931
Run random forest by Z-score standard      method / Accuracy: 0.7931

labB use Min-Max method has the highest accurancy.
accuracy: 0.7931

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7414
Run random forest by Min-Max normalization method / Accuracy: 0.7414
Run random forest by Z-score standard      method / Accuracy: 0.7241

labB use original method has the highest accurancy.
accuracy: 0.7414

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7414
Run random forest by Min-Max normalization method / Accuracy: 0.7241
Run random forest by Z-score standard      method / Accuracy: 0.7759

labB use Z-score method has the highest accurancy.
accuracy: 0.7759

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7759
Run random forest by Min-Max normalization method / Accuracy: 0.7241
Run random forest by Z-score standard      method / Accuracy: 0.7414

labB use original method has the highest accurancy.
accuracy: 0.7759

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7931
Run random forest by Min-Max normalization method / Accuracy: 0.7414
Run random forest by Z-score standard      method / Accuracy: 0.7586

labB use original method has the highest accurancy.
accuracy: 0.7931

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7414
Run random forest by Min-Max normalization method / Accuracy: 0.7931
Run random forest by Z-score standard      method / Accuracy: 0.7759

labB use Min-Max method has the highest accurancy.
accuracy: 0.7931

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7414
Run random forest by Min-Max normalization method / Accuracy: 0.7241
Run random forest by Z-score standard      method / Accuracy: 0.7241

labB use original method has the highest accurancy.
accuracy: 0.7414

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7069
Run random forest by Min-Max normalization method / Accuracy: 0.7241
Run random forest by Z-score standard      method / Accuracy: 0.6552

labB use Min-Max method has the highest accurancy.
accuracy: 0.7241

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7586
Run random forest by Min-Max normalization method / Accuracy: 0.6897
Run random forest by Z-score standard      method / Accuracy: 0.7069

labB use original method has the highest accurancy.
accuracy: 0.7586

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7586
Run random forest by Min-Max normalization method / Accuracy: 0.7414
Run random forest by Z-score standard      method / Accuracy: 0.6724

labB use original method has the highest accurancy.
accuracy: 0.7586

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.6724
Run random forest by Min-Max normalization method / Accuracy: 0.7241
Run random forest by Z-score standard      method / Accuracy: 0.6379

labB use Min-Max method has the highest accurancy.
accuracy: 0.7241

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7414
Run random forest by Min-Max normalization method / Accuracy: 0.7414
Run random forest by Z-score standard      method / Accuracy: 0.6379

labB use original method has the highest accurancy.
accuracy: 0.7414

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7414
Run random forest by Min-Max normalization method / Accuracy: 0.7414
Run random forest by Z-score standard      method / Accuracy: 0.7414

labB use original method has the highest accurancy.
accuracy: 0.7414

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7241
Run random forest by Min-Max normalization method / Accuracy: 0.7759
Run random forest by Z-score standard      method / Accuracy: 0.8103

labB use Z-score method has the highest accurancy.
accuracy: 0.8103

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7931
Run random forest by Min-Max normalization method / Accuracy: 0.7241
Run random forest by Z-score standard      method / Accuracy: 0.7931

labB use original method has the highest accurancy.
accuracy: 0.7931

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7414
Run random forest by Min-Max normalization method / Accuracy: 0.7759
Run random forest by Z-score standard      method / Accuracy: 0.7414

labB use Min-Max method has the highest accurancy.
accuracy: 0.7759

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7931
Run random forest by Min-Max normalization method / Accuracy: 0.7414
Run random forest by Z-score standard      method / Accuracy: 0.6724

labB use original method has the highest accurancy.
accuracy: 0.7931

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7069
Run random forest by Min-Max normalization method / Accuracy: 0.6897
Run random forest by Z-score standard      method / Accuracy: 0.7586

labB use Z-score method has the highest accurancy.
accuracy: 0.7586

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7241
Run random forest by Min-Max normalization method / Accuracy: 0.7241
Run random forest by Z-score standard      method / Accuracy: 0.7414

labB use Z-score method has the highest accurancy.
accuracy: 0.7414

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7414
Run random forest by Min-Max normalization method / Accuracy: 0.8103
Run random forest by Z-score standard      method / Accuracy: 0.6552

labB use Min-Max method has the highest accurancy.
accuracy: 0.8103

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7759
Run random forest by Min-Max normalization method / Accuracy: 0.7241
Run random forest by Z-score standard      method / Accuracy: 0.7241

labB use original method has the highest accurancy.
accuracy: 0.7759

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7414
Run random forest by Min-Max normalization method / Accuracy: 0.7414
Run random forest by Z-score standard      method / Accuracy: 0.7241

labB use original method has the highest accurancy.
accuracy: 0.7414

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.6897
Run random forest by Min-Max normalization method / Accuracy: 0.6897
Run random forest by Z-score standard      method / Accuracy: 0.6207

labB use original method has the highest accurancy.
accuracy: 0.6897

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7069
Run random forest by Min-Max normalization method / Accuracy: 0.7069
Run random forest by Z-score standard      method / Accuracy: 0.7759

labB use Z-score method has the highest accurancy.
accuracy: 0.7759

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7241
Run random forest by Min-Max normalization method / Accuracy: 0.7241
Run random forest by Z-score standard      method / Accuracy: 0.7586

labB use Z-score method has the highest accurancy.
accuracy: 0.7586

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7586
Run random forest by Min-Max normalization method / Accuracy: 0.7414
Run random forest by Z-score standard      method / Accuracy: 0.7414

labB use original method has the highest accurancy.
accuracy: 0.7586

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.6897
Run random forest by Min-Max normalization method / Accuracy: 0.7241
Run random forest by Z-score standard      method / Accuracy: 0.7069

labB use Min-Max method has the highest accurancy.
accuracy: 0.7241

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7931
Run random forest by Min-Max normalization method / Accuracy: 0.7414
Run random forest by Z-score standard      method / Accuracy: 0.7586

labB use original method has the highest accurancy.
accuracy: 0.7931

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7241
Run random forest by Min-Max normalization method / Accuracy: 0.7241
Run random forest by Z-score standard      method / Accuracy: 0.7241

labB use original method has the highest accurancy.
accuracy: 0.7241

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7414
Run random forest by Min-Max normalization method / Accuracy: 0.7069
Run random forest by Z-score standard      method / Accuracy: 0.7241

labB use original method has the highest accurancy.
accuracy: 0.7414

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7414
Run random forest by Min-Max normalization method / Accuracy: 0.7241
Run random forest by Z-score standard      method / Accuracy: 0.6897

labB use original method has the highest accurancy.
accuracy: 0.7414

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7586
Run random forest by Min-Max normalization method / Accuracy: 0.7414
Run random forest by Z-score standard      method / Accuracy: 0.7414

labB use original method has the highest accurancy.
accuracy: 0.7586

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7241
Run random forest by Min-Max normalization method / Accuracy: 0.7414
Run random forest by Z-score standard      method / Accuracy: 0.7586

labB use Z-score method has the highest accurancy.
accuracy: 0.7586

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.6552
Run random forest by Min-Max normalization method / Accuracy: 0.6897
Run random forest by Z-score standard      method / Accuracy: 0.7069

labB use Z-score method has the highest accurancy.
accuracy: 0.7069

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7241
Run random forest by Min-Max normalization method / Accuracy: 0.7414
Run random forest by Z-score standard      method / Accuracy: 0.7069

labB use Min-Max method has the highest accurancy.
accuracy: 0.7414

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7069
Run random forest by Min-Max normalization method / Accuracy: 0.7241
Run random forest by Z-score standard      method / Accuracy: 0.7069

labB use Min-Max method has the highest accurancy.
accuracy: 0.7241

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7586
Run random forest by Min-Max normalization method / Accuracy: 0.7759
Run random forest by Z-score standard      method / Accuracy: 0.8103

labB use Z-score method has the highest accurancy.
accuracy: 0.8103

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7414
Run random forest by Min-Max normalization method / Accuracy: 0.7241
Run random forest by Z-score standard      method / Accuracy: 0.7414

labB use original method has the highest accurancy.
accuracy: 0.7414

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7414
Run random forest by Min-Max normalization method / Accuracy: 0.7414
Run random forest by Z-score standard      method / Accuracy: 0.7586

labB use Z-score method has the highest accurancy.
accuracy: 0.7586

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7931
Run random forest by Min-Max normalization method / Accuracy: 0.7931
Run random forest by Z-score standard      method / Accuracy: 0.8103

labB use Z-score method has the highest accurancy.
accuracy: 0.8103

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7586
Run random forest by Min-Max normalization method / Accuracy: 0.7586
Run random forest by Z-score standard      method / Accuracy: 0.7414

labB use original method has the highest accurancy.
accuracy: 0.7586

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7414
Run random forest by Min-Max normalization method / Accuracy: 0.7414
Run random forest by Z-score standard      method / Accuracy: 0.7931

labB use Z-score method has the highest accurancy.
accuracy: 0.7931

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.6897
Run random forest by Min-Max normalization method / Accuracy: 0.6724
Run random forest by Z-score standard      method / Accuracy: 0.7069

labB use Z-score method has the highest accurancy.
accuracy: 0.7069

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.6897
Run random forest by Min-Max normalization method / Accuracy: 0.7069
Run random forest by Z-score standard      method / Accuracy: 0.7759

labB use Z-score method has the highest accurancy.
accuracy: 0.7759

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7586
Run random forest by Min-Max normalization method / Accuracy: 0.7241
Run random forest by Z-score standard      method / Accuracy: 0.6552

labB use original method has the highest accurancy.
accuracy: 0.7586

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7586
Run random forest by Min-Max normalization method / Accuracy: 0.7241
Run random forest by Z-score standard      method / Accuracy: 0.6897

labB use original method has the highest accurancy.
accuracy: 0.7586

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7759
Run random forest by Min-Max normalization method / Accuracy: 0.8103
Run random forest by Z-score standard      method / Accuracy: 0.7931

labB use Min-Max method has the highest accurancy.
accuracy: 0.8103

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7241
Run random forest by Min-Max normalization method / Accuracy: 0.7759
Run random forest by Z-score standard      method / Accuracy: 0.6724

labB use Min-Max method has the highest accurancy.
accuracy: 0.7759

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7586
Run random forest by Min-Max normalization method / Accuracy: 0.7586
Run random forest by Z-score standard      method / Accuracy: 0.7586

labB use original method has the highest accurancy.
accuracy: 0.7586

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7586
Run random forest by Min-Max normalization method / Accuracy: 0.7586
Run random forest by Z-score standard      method / Accuracy: 0.7586

labB use original method has the highest accurancy.
accuracy: 0.7586

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7414
Run random forest by Min-Max normalization method / Accuracy: 0.8103
Run random forest by Z-score standard      method / Accuracy: 0.8103

labB use Min-Max method has the highest accurancy.
accuracy: 0.8103

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7414
Run random forest by Min-Max normalization method / Accuracy: 0.8103
Run random forest by Z-score standard      method / Accuracy: 0.7414

labB use Min-Max method has the highest accurancy.
accuracy: 0.8103

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7931
Run random forest by Min-Max normalization method / Accuracy: 0.8448
Run random forest by Z-score standard      method / Accuracy: 0.8276

labB use Min-Max method has the highest accurancy.
accuracy: 0.8448

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7759
Run random forest by Min-Max normalization method / Accuracy: 0.7586
Run random forest by Z-score standard      method / Accuracy: 0.7931

labB use Z-score method has the highest accurancy.
accuracy: 0.7931

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.6552
Run random forest by Min-Max normalization method / Accuracy: 0.7931
Run random forest by Z-score standard      method / Accuracy: 0.7586

labB use Min-Max method has the highest accurancy.
accuracy: 0.7931

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7586
Run random forest by Min-Max normalization method / Accuracy: 0.7931
Run random forest by Z-score standard      method / Accuracy: 0.7586

labB use Min-Max method has the highest accurancy.
accuracy: 0.7931

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.6897
Run random forest by Min-Max normalization method / Accuracy: 0.7931
Run random forest by Z-score standard      method / Accuracy: 0.7586

labB use Min-Max method has the highest accurancy.
accuracy: 0.7931

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.6724
Run random forest by Min-Max normalization method / Accuracy: 0.7414
Run random forest by Z-score standard      method / Accuracy: 0.7586

labB use Z-score method has the highest accurancy.
accuracy: 0.7586

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.6552
Run random forest by Min-Max normalization method / Accuracy: 0.7241
Run random forest by Z-score standard      method / Accuracy: 0.6897

labB use Min-Max method has the highest accurancy.
accuracy: 0.7241

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7414
Run random forest by Min-Max normalization method / Accuracy: 0.7241
Run random forest by Z-score standard      method / Accuracy: 0.7759

labB use Z-score method has the highest accurancy.
accuracy: 0.7759

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7069
Run random forest by Min-Max normalization method / Accuracy: 0.7069
Run random forest by Z-score standard      method / Accuracy: 0.6897

labB use original method has the highest accurancy.
accuracy: 0.7069

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7414
Run random forest by Min-Max normalization method / Accuracy: 0.8103
Run random forest by Z-score standard      method / Accuracy: 0.7069

labB use Min-Max method has the highest accurancy.
accuracy: 0.8103

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7931
Run random forest by Min-Max normalization method / Accuracy: 0.7414
Run random forest by Z-score standard      method / Accuracy: 0.7759

labB use original method has the highest accurancy.
accuracy: 0.7931

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7586
Run random forest by Min-Max normalization method / Accuracy: 0.7759
Run random forest by Z-score standard      method / Accuracy: 0.7586

labB use Min-Max method has the highest accurancy.
accuracy: 0.7759

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7586
Run random forest by Min-Max normalization method / Accuracy: 0.7241
Run random forest by Z-score standard      method / Accuracy: 0.7586

labB use original method has the highest accurancy.
accuracy: 0.7586

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7414
Run random forest by Min-Max normalization method / Accuracy: 0.7241
Run random forest by Z-score standard      method / Accuracy: 0.7241

labB use original method has the highest accurancy.
accuracy: 0.7414

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7759
Run random forest by Min-Max normalization method / Accuracy: 0.7586
Run random forest by Z-score standard      method / Accuracy: 0.8103

labB use Z-score method has the highest accurancy.
accuracy: 0.8103

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7586
Run random forest by Min-Max normalization method / Accuracy: 0.7069
Run random forest by Z-score standard      method / Accuracy: 0.7069

labB use original method has the highest accurancy.
accuracy: 0.7586

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7241
Run random forest by Min-Max normalization method / Accuracy: 0.7586
Run random forest by Z-score standard      method / Accuracy: 0.7241

labB use Min-Max method has the highest accurancy.
accuracy: 0.7586

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7759
Run random forest by Min-Max normalization method / Accuracy: 0.7414
Run random forest by Z-score standard      method / Accuracy: 0.7241

labB use original method has the highest accurancy.
accuracy: 0.7759

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7586
Run random forest by Min-Max normalization method / Accuracy: 0.7586
Run random forest by Z-score standard      method / Accuracy: 0.7759

labB use Z-score method has the highest accurancy.
accuracy: 0.7759

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7931
Run random forest by Min-Max normalization method / Accuracy: 0.7759
Run random forest by Z-score standard      method / Accuracy: 0.7759

labB use original method has the highest accurancy.
accuracy: 0.7931

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7759
Run random forest by Min-Max normalization method / Accuracy: 0.7586
Run random forest by Z-score standard      method / Accuracy: 0.7759

labB use original method has the highest accurancy.
accuracy: 0.7759

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7586
Run random forest by Min-Max normalization method / Accuracy: 0.7759
Run random forest by Z-score standard      method / Accuracy: 0.7241

labB use Min-Max method has the highest accurancy.
accuracy: 0.7759

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7759
Run random forest by Min-Max normalization method / Accuracy: 0.7759
Run random forest by Z-score standard      method / Accuracy: 0.7586

labB use original method has the highest accurancy.
accuracy: 0.7759

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7586
Run random forest by Min-Max normalization method / Accuracy: 0.7586
Run random forest by Z-score standard      method / Accuracy: 0.7241

labB use original method has the highest accurancy.
accuracy: 0.7586

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52

Balancing data by over sampling...
original training data class 0: 233 / class 1: 107
original testing  data class 0:  29 / class 1:  23
balanced training data class 0: 233 / class 1: 233
balanced testing  data class 0:  29 / class 1:  29
===========================================================================
Run random forest by original              method / Accuracy: 0.7759
Run random forest by Min-Max normalization method / Accuracy: 0.7586
Run random forest by Z-score standard      method / Accuracy: 0.7759

labB use original method has the highest accurancy.
accuracy: 0.7759

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value = 10 Accuracy: 0.8182
Run KNN by Min-Max normalization method / k value =  6 Accuracy: 0.8485
Run KNN by Z-score standard      method / k value = 14 Accuracy: 0.8485

labA use Min-Max method has the highest accurancy.
accuracy: 0.8485 / k = 6

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute KNN algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Each method search best k value in 1 ~ 30
Run KNN by original              method / k value =  7 Accuracy: 0.7692
Run KNN by Min-Max normalization method / k value = 12 Accuracy: 0.7885
Run KNN by Z-score standard      method / k value =  9 Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885 / k = 12

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8384
Run random forest by Min-Max normalization method / Accuracy: 0.7576
Run random forest by Z-score standard      method / Accuracy: 0.8182

labA use original method has the highest accurancy.
accuracy: 0.8384

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8485
Run random forest by Min-Max normalization method / Accuracy: 0.7677
Run random forest by Z-score standard      method / Accuracy: 0.8283

labA use original method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8283
Run random forest by Min-Max normalization method / Accuracy: 0.7475
Run random forest by Z-score standard      method / Accuracy: 0.8384

labA use Z-score method has the highest accurancy.
accuracy: 0.8384

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8586
Run random forest by Min-Max normalization method / Accuracy: 0.7475
Run random forest by Z-score standard      method / Accuracy: 0.8485

labA use original method has the highest accurancy.
accuracy: 0.8586

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8283
Run random forest by Min-Max normalization method / Accuracy: 0.7677
Run random forest by Z-score standard      method / Accuracy: 0.8384

labA use Z-score method has the highest accurancy.
accuracy: 0.8384

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8182
Run random forest by Min-Max normalization method / Accuracy: 0.7374
Run random forest by Z-score standard      method / Accuracy: 0.8384

labA use Z-score method has the highest accurancy.
accuracy: 0.8384

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8485
Run random forest by Min-Max normalization method / Accuracy: 0.7172
Run random forest by Z-score standard      method / Accuracy: 0.8485

labA use original method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8283
Run random forest by Min-Max normalization method / Accuracy: 0.7172
Run random forest by Z-score standard      method / Accuracy: 0.8182

labA use original method has the highest accurancy.
accuracy: 0.8283

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8182
Run random forest by Min-Max normalization method / Accuracy: 0.7374
Run random forest by Z-score standard      method / Accuracy: 0.8384

labA use Z-score method has the highest accurancy.
accuracy: 0.8384

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8384
Run random forest by Min-Max normalization method / Accuracy: 0.7172
Run random forest by Z-score standard      method / Accuracy: 0.8485

labA use Z-score method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8081
Run random forest by Min-Max normalization method / Accuracy: 0.7475
Run random forest by Z-score standard      method / Accuracy: 0.8384

labA use Z-score method has the highest accurancy.
accuracy: 0.8384

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8182
Run random forest by Min-Max normalization method / Accuracy: 0.7273
Run random forest by Z-score standard      method / Accuracy: 0.8485

labA use Z-score method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8384
Run random forest by Min-Max normalization method / Accuracy: 0.6869
Run random forest by Z-score standard      method / Accuracy: 0.8384

labA use original method has the highest accurancy.
accuracy: 0.8384

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8485
Run random forest by Min-Max normalization method / Accuracy: 0.7475
Run random forest by Z-score standard      method / Accuracy: 0.8384

labA use original method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8182
Run random forest by Min-Max normalization method / Accuracy: 0.7576
Run random forest by Z-score standard      method / Accuracy: 0.8485

labA use Z-score method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8283
Run random forest by Min-Max normalization method / Accuracy: 0.7172
Run random forest by Z-score standard      method / Accuracy: 0.8182

labA use original method has the highest accurancy.
accuracy: 0.8283

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8081
Run random forest by Min-Max normalization method / Accuracy: 0.7172
Run random forest by Z-score standard      method / Accuracy: 0.8485

labA use Z-score method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8384
Run random forest by Min-Max normalization method / Accuracy: 0.7172
Run random forest by Z-score standard      method / Accuracy: 0.8485

labA use Z-score method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8485
Run random forest by Min-Max normalization method / Accuracy: 0.7374
Run random forest by Z-score standard      method / Accuracy: 0.8384

labA use original method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8283
Run random forest by Min-Max normalization method / Accuracy: 0.7273
Run random forest by Z-score standard      method / Accuracy: 0.8485

labA use Z-score method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8384
Run random forest by Min-Max normalization method / Accuracy: 0.7172
Run random forest by Z-score standard      method / Accuracy: 0.8384

labA use original method has the highest accurancy.
accuracy: 0.8384

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8283
Run random forest by Min-Max normalization method / Accuracy: 0.7273
Run random forest by Z-score standard      method / Accuracy: 0.8485

labA use Z-score method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8283
Run random forest by Min-Max normalization method / Accuracy: 0.6970
Run random forest by Z-score standard      method / Accuracy: 0.8283

labA use original method has the highest accurancy.
accuracy: 0.8283

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8384
Run random forest by Min-Max normalization method / Accuracy: 0.7475
Run random forest by Z-score standard      method / Accuracy: 0.8283

labA use original method has the highest accurancy.
accuracy: 0.8384

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8182
Run random forest by Min-Max normalization method / Accuracy: 0.7475
Run random forest by Z-score standard      method / Accuracy: 0.8485

labA use Z-score method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8182
Run random forest by Min-Max normalization method / Accuracy: 0.7677
Run random forest by Z-score standard      method / Accuracy: 0.8384

labA use Z-score method has the highest accurancy.
accuracy: 0.8384

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8384
Run random forest by Min-Max normalization method / Accuracy: 0.7071
Run random forest by Z-score standard      method / Accuracy: 0.8485

labA use Z-score method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8485
Run random forest by Min-Max normalization method / Accuracy: 0.7172
Run random forest by Z-score standard      method / Accuracy: 0.8182

labA use original method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8283
Run random forest by Min-Max normalization method / Accuracy: 0.6970
Run random forest by Z-score standard      method / Accuracy: 0.8283

labA use original method has the highest accurancy.
accuracy: 0.8283

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8081
Run random forest by Min-Max normalization method / Accuracy: 0.7374
Run random forest by Z-score standard      method / Accuracy: 0.8182

labA use Z-score method has the highest accurancy.
accuracy: 0.8182

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8182
Run random forest by Min-Max normalization method / Accuracy: 0.7273
Run random forest by Z-score standard      method / Accuracy: 0.8384

labA use Z-score method has the highest accurancy.
accuracy: 0.8384

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8384
Run random forest by Min-Max normalization method / Accuracy: 0.7071
Run random forest by Z-score standard      method / Accuracy: 0.8182

labA use original method has the highest accurancy.
accuracy: 0.8384

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8283
Run random forest by Min-Max normalization method / Accuracy: 0.7677
Run random forest by Z-score standard      method / Accuracy: 0.8485

labA use Z-score method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8384
Run random forest by Min-Max normalization method / Accuracy: 0.7475
Run random forest by Z-score standard      method / Accuracy: 0.8182

labA use original method has the highest accurancy.
accuracy: 0.8384

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8485
Run random forest by Min-Max normalization method / Accuracy: 0.6970
Run random forest by Z-score standard      method / Accuracy: 0.8283

labA use original method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8485
Run random forest by Min-Max normalization method / Accuracy: 0.7475
Run random forest by Z-score standard      method / Accuracy: 0.8485

labA use original method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8081
Run random forest by Min-Max normalization method / Accuracy: 0.7273
Run random forest by Z-score standard      method / Accuracy: 0.8283

labA use Z-score method has the highest accurancy.
accuracy: 0.8283

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8081
Run random forest by Min-Max normalization method / Accuracy: 0.7273
Run random forest by Z-score standard      method / Accuracy: 0.8081

labA use original method has the highest accurancy.
accuracy: 0.8081

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8485
Run random forest by Min-Max normalization method / Accuracy: 0.7273
Run random forest by Z-score standard      method / Accuracy: 0.8384

labA use original method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8384
Run random forest by Min-Max normalization method / Accuracy: 0.7374
Run random forest by Z-score standard      method / Accuracy: 0.8384

labA use original method has the highest accurancy.
accuracy: 0.8384

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8283
Run random forest by Min-Max normalization method / Accuracy: 0.7172
Run random forest by Z-score standard      method / Accuracy: 0.8283

labA use original method has the highest accurancy.
accuracy: 0.8283

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8485
Run random forest by Min-Max normalization method / Accuracy: 0.7374
Run random forest by Z-score standard      method / Accuracy: 0.8384

labA use original method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8586
Run random forest by Min-Max normalization method / Accuracy: 0.7475
Run random forest by Z-score standard      method / Accuracy: 0.8182

labA use original method has the highest accurancy.
accuracy: 0.8586

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.7980
Run random forest by Min-Max normalization method / Accuracy: 0.7374
Run random forest by Z-score standard      method / Accuracy: 0.8485

labA use Z-score method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.7980
Run random forest by Min-Max normalization method / Accuracy: 0.7374
Run random forest by Z-score standard      method / Accuracy: 0.8384

labA use Z-score method has the highest accurancy.
accuracy: 0.8384

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8687
Run random forest by Min-Max normalization method / Accuracy: 0.7172
Run random forest by Z-score standard      method / Accuracy: 0.8283

labA use original method has the highest accurancy.
accuracy: 0.8687

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8485
Run random forest by Min-Max normalization method / Accuracy: 0.7475
Run random forest by Z-score standard      method / Accuracy: 0.8384

labA use original method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8182
Run random forest by Min-Max normalization method / Accuracy: 0.7677
Run random forest by Z-score standard      method / Accuracy: 0.8283

labA use Z-score method has the highest accurancy.
accuracy: 0.8283

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8384
Run random forest by Min-Max normalization method / Accuracy: 0.7172
Run random forest by Z-score standard      method / Accuracy: 0.8485

labA use Z-score method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8081
Run random forest by Min-Max normalization method / Accuracy: 0.7273
Run random forest by Z-score standard      method / Accuracy: 0.8283

labA use Z-score method has the highest accurancy.
accuracy: 0.8283

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8283
Run random forest by Min-Max normalization method / Accuracy: 0.7475
Run random forest by Z-score standard      method / Accuracy: 0.8485

labA use Z-score method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8384
Run random forest by Min-Max normalization method / Accuracy: 0.7172
Run random forest by Z-score standard      method / Accuracy: 0.7980

labA use original method has the highest accurancy.
accuracy: 0.8384

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8283
Run random forest by Min-Max normalization method / Accuracy: 0.7374
Run random forest by Z-score standard      method / Accuracy: 0.8485

labA use Z-score method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8182
Run random forest by Min-Max normalization method / Accuracy: 0.7475
Run random forest by Z-score standard      method / Accuracy: 0.8182

labA use original method has the highest accurancy.
accuracy: 0.8182

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8081
Run random forest by Min-Max normalization method / Accuracy: 0.7273
Run random forest by Z-score standard      method / Accuracy: 0.8283

labA use Z-score method has the highest accurancy.
accuracy: 0.8283

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8182
Run random forest by Min-Max normalization method / Accuracy: 0.7374
Run random forest by Z-score standard      method / Accuracy: 0.8182

labA use original method has the highest accurancy.
accuracy: 0.8182

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8384
Run random forest by Min-Max normalization method / Accuracy: 0.7273
Run random forest by Z-score standard      method / Accuracy: 0.8283

labA use original method has the highest accurancy.
accuracy: 0.8384

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8384
Run random forest by Min-Max normalization method / Accuracy: 0.7071
Run random forest by Z-score standard      method / Accuracy: 0.8384

labA use original method has the highest accurancy.
accuracy: 0.8384

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8384
Run random forest by Min-Max normalization method / Accuracy: 0.7273
Run random forest by Z-score standard      method / Accuracy: 0.8485

labA use Z-score method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8182
Run random forest by Min-Max normalization method / Accuracy: 0.7172
Run random forest by Z-score standard      method / Accuracy: 0.8182

labA use original method has the highest accurancy.
accuracy: 0.8182

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8283
Run random forest by Min-Max normalization method / Accuracy: 0.7273
Run random forest by Z-score standard      method / Accuracy: 0.8283

labA use original method has the highest accurancy.
accuracy: 0.8283

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8182
Run random forest by Min-Max normalization method / Accuracy: 0.7778
Run random forest by Z-score standard      method / Accuracy: 0.8384

labA use Z-score method has the highest accurancy.
accuracy: 0.8384

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8182
Run random forest by Min-Max normalization method / Accuracy: 0.7273
Run random forest by Z-score standard      method / Accuracy: 0.8485

labA use Z-score method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8283
Run random forest by Min-Max normalization method / Accuracy: 0.7576
Run random forest by Z-score standard      method / Accuracy: 0.8485

labA use Z-score method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8182
Run random forest by Min-Max normalization method / Accuracy: 0.7273
Run random forest by Z-score standard      method / Accuracy: 0.8182

labA use original method has the highest accurancy.
accuracy: 0.8182

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.7980
Run random forest by Min-Max normalization method / Accuracy: 0.7879
Run random forest by Z-score standard      method / Accuracy: 0.8283

labA use Z-score method has the highest accurancy.
accuracy: 0.8283

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8384
Run random forest by Min-Max normalization method / Accuracy: 0.7475
Run random forest by Z-score standard      method / Accuracy: 0.8384

labA use original method has the highest accurancy.
accuracy: 0.8384

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.7778
Run random forest by Min-Max normalization method / Accuracy: 0.7273
Run random forest by Z-score standard      method / Accuracy: 0.8182

labA use Z-score method has the highest accurancy.
accuracy: 0.8182

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8384
Run random forest by Min-Max normalization method / Accuracy: 0.7374
Run random forest by Z-score standard      method / Accuracy: 0.8485

labA use Z-score method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8485
Run random forest by Min-Max normalization method / Accuracy: 0.7374
Run random forest by Z-score standard      method / Accuracy: 0.8182

labA use original method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8283
Run random forest by Min-Max normalization method / Accuracy: 0.7475
Run random forest by Z-score standard      method / Accuracy: 0.8283

labA use original method has the highest accurancy.
accuracy: 0.8283

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8182
Run random forest by Min-Max normalization method / Accuracy: 0.7475
Run random forest by Z-score standard      method / Accuracy: 0.8283

labA use Z-score method has the highest accurancy.
accuracy: 0.8283

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8283
Run random forest by Min-Max normalization method / Accuracy: 0.7374
Run random forest by Z-score standard      method / Accuracy: 0.8182

labA use original method has the highest accurancy.
accuracy: 0.8283

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8182
Run random forest by Min-Max normalization method / Accuracy: 0.7273
Run random forest by Z-score standard      method / Accuracy: 0.8283

labA use Z-score method has the highest accurancy.
accuracy: 0.8283

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8081
Run random forest by Min-Max normalization method / Accuracy: 0.7071
Run random forest by Z-score standard      method / Accuracy: 0.8283

labA use Z-score method has the highest accurancy.
accuracy: 0.8283

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8384
Run random forest by Min-Max normalization method / Accuracy: 0.7576
Run random forest by Z-score standard      method / Accuracy: 0.8283

labA use original method has the highest accurancy.
accuracy: 0.8384

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8283
Run random forest by Min-Max normalization method / Accuracy: 0.7172
Run random forest by Z-score standard      method / Accuracy: 0.8182

labA use original method has the highest accurancy.
accuracy: 0.8283

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8081
Run random forest by Min-Max normalization method / Accuracy: 0.7576
Run random forest by Z-score standard      method / Accuracy: 0.8384

labA use Z-score method has the highest accurancy.
accuracy: 0.8384

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8283
Run random forest by Min-Max normalization method / Accuracy: 0.7273
Run random forest by Z-score standard      method / Accuracy: 0.8283

labA use original method has the highest accurancy.
accuracy: 0.8283

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8182
Run random forest by Min-Max normalization method / Accuracy: 0.7475
Run random forest by Z-score standard      method / Accuracy: 0.8283

labA use Z-score method has the highest accurancy.
accuracy: 0.8283

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8485
Run random forest by Min-Max normalization method / Accuracy: 0.7374
Run random forest by Z-score standard      method / Accuracy: 0.8182

labA use original method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8283
Run random forest by Min-Max normalization method / Accuracy: 0.7677
Run random forest by Z-score standard      method / Accuracy: 0.8283

labA use original method has the highest accurancy.
accuracy: 0.8283

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8182
Run random forest by Min-Max normalization method / Accuracy: 0.7374
Run random forest by Z-score standard      method / Accuracy: 0.8384

labA use Z-score method has the highest accurancy.
accuracy: 0.8384

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8182
Run random forest by Min-Max normalization method / Accuracy: 0.7273
Run random forest by Z-score standard      method / Accuracy: 0.8586

labA use Z-score method has the highest accurancy.
accuracy: 0.8586

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8485
Run random forest by Min-Max normalization method / Accuracy: 0.7677
Run random forest by Z-score standard      method / Accuracy: 0.8384

labA use original method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8182
Run random forest by Min-Max normalization method / Accuracy: 0.7374
Run random forest by Z-score standard      method / Accuracy: 0.8485

labA use Z-score method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8283
Run random forest by Min-Max normalization method / Accuracy: 0.7576
Run random forest by Z-score standard      method / Accuracy: 0.8485

labA use Z-score method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8384
Run random forest by Min-Max normalization method / Accuracy: 0.6970
Run random forest by Z-score standard      method / Accuracy: 0.8384

labA use original method has the highest accurancy.
accuracy: 0.8384

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8586
Run random forest by Min-Max normalization method / Accuracy: 0.7374
Run random forest by Z-score standard      method / Accuracy: 0.8384

labA use original method has the highest accurancy.
accuracy: 0.8586

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8384
Run random forest by Min-Max normalization method / Accuracy: 0.7576
Run random forest by Z-score standard      method / Accuracy: 0.8283

labA use original method has the highest accurancy.
accuracy: 0.8384

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8485
Run random forest by Min-Max normalization method / Accuracy: 0.7475
Run random forest by Z-score standard      method / Accuracy: 0.8283

labA use original method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8081
Run random forest by Min-Max normalization method / Accuracy: 0.7273
Run random forest by Z-score standard      method / Accuracy: 0.8182

labA use Z-score method has the highest accurancy.
accuracy: 0.8182

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8081
Run random forest by Min-Max normalization method / Accuracy: 0.7374
Run random forest by Z-score standard      method / Accuracy: 0.8182

labA use Z-score method has the highest accurancy.
accuracy: 0.8182

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8384
Run random forest by Min-Max normalization method / Accuracy: 0.6970
Run random forest by Z-score standard      method / Accuracy: 0.8283

labA use original method has the highest accurancy.
accuracy: 0.8384

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8182
Run random forest by Min-Max normalization method / Accuracy: 0.7374
Run random forest by Z-score standard      method / Accuracy: 0.8283

labA use Z-score method has the highest accurancy.
accuracy: 0.8283

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8182
Run random forest by Min-Max normalization method / Accuracy: 0.7576
Run random forest by Z-score standard      method / Accuracy: 0.8586

labA use Z-score method has the highest accurancy.
accuracy: 0.8586

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8283
Run random forest by Min-Max normalization method / Accuracy: 0.7071
Run random forest by Z-score standard      method / Accuracy: 0.8384

labA use Z-score method has the highest accurancy.
accuracy: 0.8384

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8182
Run random forest by Min-Max normalization method / Accuracy: 0.7475
Run random forest by Z-score standard      method / Accuracy: 0.8283

labA use Z-score method has the highest accurancy.
accuracy: 0.8283

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8283
Run random forest by Min-Max normalization method / Accuracy: 0.7374
Run random forest by Z-score standard      method / Accuracy: 0.8384

labA use Z-score method has the highest accurancy.
accuracy: 0.8384

Don't plot the result

Excute RandomForest algorithm...

datasets from labA
===========================================================================
Loading datasets...
The original training data have 567.
The original testing  data have 201.

Cleaning data...
clean original training data: 567 -> 293
clean original testing  data: 201 ->  99
===========================================================================
Run random forest by original              method / Accuracy: 0.8182
Run random forest by Min-Max normalization method / Accuracy: 0.7576
Run random forest by Z-score standard      method / Accuracy: 0.8485

labA use Z-score method has the highest accurancy.
accuracy: 0.8485

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Z-score method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.7500

labB use original method has the highest accurancy.
accuracy: 0.7500

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.7692
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Min-Max method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.8077
Run random forest by Z-score standard      method / Accuracy: 0.7308

labB use Min-Max method has the highest accurancy.
accuracy: 0.8077

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.7500

labB use original method has the highest accurancy.
accuracy: 0.7500

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7115
Run random forest by Min-Max normalization method / Accuracy: 0.7692
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Min-Max method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.7885
Run random forest by Z-score standard      method / Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.7885
Run random forest by Z-score standard      method / Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7115
Run random forest by Min-Max normalization method / Accuracy: 0.7692
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Min-Max method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.8077
Run random forest by Min-Max normalization method / Accuracy: 0.7692
Run random forest by Z-score standard      method / Accuracy: 0.7500

labB use original method has the highest accurancy.
accuracy: 0.8077

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7692
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use original method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.7692
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Min-Max method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.7308
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Z-score method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7885
Run random forest by Min-Max normalization method / Accuracy: 0.7308
Run random forest by Z-score standard      method / Accuracy: 0.7308

labB use original method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7308
Run random forest by Min-Max normalization method / Accuracy: 0.7885
Run random forest by Z-score standard      method / Accuracy: 0.7885

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7692
Run random forest by Min-Max normalization method / Accuracy: 0.8077
Run random forest by Z-score standard      method / Accuracy: 0.7885

labB use Min-Max method has the highest accurancy.
accuracy: 0.8077

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.7692
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Min-Max method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7692
Run random forest by Min-Max normalization method / Accuracy: 0.7885
Run random forest by Z-score standard      method / Accuracy: 0.8077

labB use Z-score method has the highest accurancy.
accuracy: 0.8077

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7885
Run random forest by Min-Max normalization method / Accuracy: 0.7885
Run random forest by Z-score standard      method / Accuracy: 0.7885

labB use original method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7692
Run random forest by Min-Max normalization method / Accuracy: 0.7692
Run random forest by Z-score standard      method / Accuracy: 0.7308

labB use original method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7692
Run random forest by Min-Max normalization method / Accuracy: 0.8462
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Min-Max method has the highest accurancy.
accuracy: 0.8462

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7308
Run random forest by Min-Max normalization method / Accuracy: 0.8077
Run random forest by Z-score standard      method / Accuracy: 0.7885

labB use Min-Max method has the highest accurancy.
accuracy: 0.8077

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7308
Run random forest by Min-Max normalization method / Accuracy: 0.8077
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Min-Max method has the highest accurancy.
accuracy: 0.8077

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.8269
Run random forest by Z-score standard      method / Accuracy: 0.7885

labB use Min-Max method has the highest accurancy.
accuracy: 0.8269

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7308
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Z-score method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7692
Run random forest by Min-Max normalization method / Accuracy: 0.7692
Run random forest by Z-score standard      method / Accuracy: 0.7500

labB use original method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Z-score method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7885
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use original method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7692
Run random forest by Min-Max normalization method / Accuracy: 0.7885
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7885
Run random forest by Min-Max normalization method / Accuracy: 0.8462
Run random forest by Z-score standard      method / Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.8462

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7692
Run random forest by Min-Max normalization method / Accuracy: 0.7692
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use original method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7115
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.7885

labB use Z-score method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.8077
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Min-Max method has the highest accurancy.
accuracy: 0.8077

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7692
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use original method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7308
Run random forest by Min-Max normalization method / Accuracy: 0.7885
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7308
Run random forest by Min-Max normalization method / Accuracy: 0.7692
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Min-Max method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.7885
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Z-score method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7692
Run random forest by Min-Max normalization method / Accuracy: 0.7885
Run random forest by Z-score standard      method / Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.7308
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Z-score method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7692
Run random forest by Min-Max normalization method / Accuracy: 0.7115
Run random forest by Z-score standard      method / Accuracy: 0.7500

labB use original method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7115
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Z-score method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.7115
Run random forest by Z-score standard      method / Accuracy: 0.7500

labB use original method has the highest accurancy.
accuracy: 0.7500

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7885
Run random forest by Min-Max normalization method / Accuracy: 0.7692
Run random forest by Z-score standard      method / Accuracy: 0.7500

labB use original method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.7885
Run random forest by Z-score standard      method / Accuracy: 0.7885

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7308
Run random forest by Min-Max normalization method / Accuracy: 0.7692
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Min-Max method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7115
Run random forest by Min-Max normalization method / Accuracy: 0.7692
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Min-Max method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.7885
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.7885
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7308
Run random forest by Min-Max normalization method / Accuracy: 0.7308
Run random forest by Z-score standard      method / Accuracy: 0.7885

labB use Z-score method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.7692
Run random forest by Z-score standard      method / Accuracy: 0.7115

labB use Min-Max method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7885
Run random forest by Min-Max normalization method / Accuracy: 0.7115
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use original method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7115
Run random forest by Min-Max normalization method / Accuracy: 0.7692
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Min-Max method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7115
Run random forest by Min-Max normalization method / Accuracy: 0.8077
Run random forest by Z-score standard      method / Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.8077

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7308
Run random forest by Min-Max normalization method / Accuracy: 0.8077
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Min-Max method has the highest accurancy.
accuracy: 0.8077

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7885
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.7885

labB use original method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.8654
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Min-Max method has the highest accurancy.
accuracy: 0.8654

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7885
Run random forest by Min-Max normalization method / Accuracy: 0.8077
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Min-Max method has the highest accurancy.
accuracy: 0.8077

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.7885
Run random forest by Z-score standard      method / Accuracy: 0.7885

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7692
Run random forest by Min-Max normalization method / Accuracy: 0.8077
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Min-Max method has the highest accurancy.
accuracy: 0.8077

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7692
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.7308

labB use original method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.7308
Run random forest by Z-score standard      method / Accuracy: 0.7500

labB use original method has the highest accurancy.
accuracy: 0.7500

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7885
Run random forest by Min-Max normalization method / Accuracy: 0.7308
Run random forest by Z-score standard      method / Accuracy: 0.7308

labB use original method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.7500

labB use original method has the highest accurancy.
accuracy: 0.7500

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7692
Run random forest by Min-Max normalization method / Accuracy: 0.8077
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Min-Max method has the highest accurancy.
accuracy: 0.8077

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7308
Run random forest by Min-Max normalization method / Accuracy: 0.7308
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Z-score method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Z-score method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.7692
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Min-Max method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7308
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.7885

labB use Z-score method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.7692
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Min-Max method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7885
Run random forest by Min-Max normalization method / Accuracy: 0.7115
Run random forest by Z-score standard      method / Accuracy: 0.7500

labB use original method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7308
Run random forest by Min-Max normalization method / Accuracy: 0.7115
Run random forest by Z-score standard      method / Accuracy: 0.7308

labB use original method has the highest accurancy.
accuracy: 0.7308

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7692
Run random forest by Min-Max normalization method / Accuracy: 0.7308
Run random forest by Z-score standard      method / Accuracy: 0.7500

labB use original method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7115
Run random forest by Min-Max normalization method / Accuracy: 0.7115
Run random forest by Z-score standard      method / Accuracy: 0.7885

labB use Z-score method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.7115
Run random forest by Z-score standard      method / Accuracy: 0.7885

labB use Z-score method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7692
Run random forest by Min-Max normalization method / Accuracy: 0.7885
Run random forest by Z-score standard      method / Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7115
Run random forest by Min-Max normalization method / Accuracy: 0.7692
Run random forest by Z-score standard      method / Accuracy: 0.7885

labB use Z-score method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7308
Run random forest by Min-Max normalization method / Accuracy: 0.7885
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7692
Run random forest by Min-Max normalization method / Accuracy: 0.7885
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7115
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.7885

labB use Z-score method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7692
Run random forest by Min-Max normalization method / Accuracy: 0.7308
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use original method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.8462
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Min-Max method has the highest accurancy.
accuracy: 0.8462

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7692
Run random forest by Min-Max normalization method / Accuracy: 0.7115
Run random forest by Z-score standard      method / Accuracy: 0.7500

labB use original method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7692
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use original method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7308
Run random forest by Min-Max normalization method / Accuracy: 0.7885
Run random forest by Z-score standard      method / Accuracy: 0.7308

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7692
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use original method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7308
Run random forest by Min-Max normalization method / Accuracy: 0.8077
Run random forest by Z-score standard      method / Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.8077

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7308
Run random forest by Min-Max normalization method / Accuracy: 0.7308
Run random forest by Z-score standard      method / Accuracy: 0.7500

labB use Z-score method has the highest accurancy.
accuracy: 0.7500

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7692
Run random forest by Min-Max normalization method / Accuracy: 0.7308
Run random forest by Z-score standard      method / Accuracy: 0.7115

labB use original method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7692
Run random forest by Min-Max normalization method / Accuracy: 0.8077
Run random forest by Z-score standard      method / Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.8077

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7308
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Z-score method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7885
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.7500

labB use original method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.7692
Run random forest by Z-score standard      method / Accuracy: 0.7885

labB use Z-score method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7885
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use original method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.8269
Run random forest by Z-score standard      method / Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.8269

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7885
Run random forest by Min-Max normalization method / Accuracy: 0.7500
Run random forest by Z-score standard      method / Accuracy: 0.8077

labB use Z-score method has the highest accurancy.
accuracy: 0.8077

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.7885
Run random forest by Z-score standard      method / Accuracy: 0.7500

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7115
Run random forest by Min-Max normalization method / Accuracy: 0.7692
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Min-Max method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7500
Run random forest by Min-Max normalization method / Accuracy: 0.7692
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Min-Max method has the highest accurancy.
accuracy: 0.7692

Don't plot the result

Excute RandomForest algorithm...

datasets from labB
===========================================================================
Loading datasets...
The original training data have 668.
The original testing  data have 100.

Cleaning data...
clean original training data: 668 -> 340
clean original testing  data: 100 ->  52
===========================================================================
Run random forest by original              method / Accuracy: 0.7308
Run random forest by Min-Max normalization method / Accuracy: 0.7885
Run random forest by Z-score standard      method / Accuracy: 0.7692

labB use Min-Max method has the highest accurancy.
accuracy: 0.7885

Don't plot the result

KNN algorithm in labA with data balance repeat 100 times
1. original data
average accuracy: 80.65% / max accuracy: 80.65%
2. Min-Max normalization
average accuracy: 83.87% / max accuracy: 83.87%
3. Z-score standard
average accuracy: 88.71% / max accuracy: 88.71%
===========================================================================
KNN algorithm in labB with data balance repeat 100 times
1. original data
average accuracy: 80.43% / max accuracy: 80.43%
2. Min-Max normalization
average accuracy: 78.26% / max accuracy: 78.26%
3. Z-score standard
average accuracy: 80.43% / max accuracy: 80.43%
===========================================================================
RandomForest algorithm in labA with data balance repeat 100 times
1. original data
average accuracy: 80.68% / max accuracy: 88.24%
2. Min-Max normalization
average accuracy: 75.18% / max accuracy: 80.15%
3. Z-score standard
average accuracy: 80.39% / max accuracy: 87.50%
===========================================================================
RandomForest algorithm in labB with data balance repeat 100 times
1. original data
average accuracy: 74.33% / max accuracy: 82.76%
2. Min-Max normalization
average accuracy: 74.60% / max accuracy: 84.48%
3. Z-score standard
average accuracy: 73.90% / max accuracy: 82.76%
===========================================================================
KNN algorithm in labA without data balance repeat 100 times
1. original data
average accuracy: 81.82% / max accuracy: 81.82%
2. Min-Max normalization
average accuracy: 84.85% / max accuracy: 84.85%
3. Z-score standard
average accuracy: 84.85% / max accuracy: 84.85%
===========================================================================
KNN algorithm in labB without data balance repeat 100 times
1. original data
average accuracy: 76.92% / max accuracy: 76.92%
2. Min-Max normalization
average accuracy: 78.85% / max accuracy: 78.85%
3. Z-score standard
average accuracy: 75.00% / max accuracy: 75.00%
===========================================================================
RandomForest algorithm in labA without data balance repeat 100 times
1. original data
average accuracy: 82.85% / max accuracy: 86.87%
2. Min-Max normalization
average accuracy: 73.53% / max accuracy: 78.79%
3. Z-score standard
average accuracy: 83.39% / max accuracy: 85.86%
===========================================================================
RandomForest algorithm in labB without data balance repeat 100 times
1. original data
average accuracy: 75.23% / max accuracy: 80.77%
2. Min-Max normalization
average accuracy: 76.87% / max accuracy: 86.54%
3. Z-score standard
average accuracy: 76.46% / max accuracy: 80.77%
===========================================================================
Execution time: 166.9490 s
